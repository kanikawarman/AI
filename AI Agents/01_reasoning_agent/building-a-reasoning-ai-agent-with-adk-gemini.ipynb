{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building a Reasoning AI Agent with ADK & Gemini\n\n## Project Objective\n\nThis project showcases the development of a reasoning-capable AI agent built using Google‚Äôs Agent Development Kit (ADK) and Gemini large language models. The agent is designed to autonomously interpret queries, make decisions, and invoke external tools to deliver grounded, contextual responses.\n\nThrough this implementation, I demonstrate practical expertise in agentic AI design, including environment setup, reasoning loop construction, tool orchestration, and real-time interaction. The notebook serves as an end-to-end demonstration of how to operationalize modern LLM-powered agents for dynamic task execution and intelligent decision-making.","metadata":{}},{"cell_type":"markdown","source":"## Overview: Project Highlights\n\nThis project demonstrates the end-to-end process of building an intelligent reasoning agent powered by Google‚Äôs Agent Development Kit (ADK) and Gemini models. The agent autonomously reasons through queries, invokes external tools, and adapts its responses based on real-time information.\n\n**Project Workflow**\n\n**Environment Setup** ‚Äî Configured secure API authentication and integrated core dependencies for Gemini-powered agent execution.\n\n**Agent Configuration** ‚Äî Implemented a reasoning agent with dynamic tool selection (e.g., Google Search) and robust retry logic for rate-limited APIs.\n\n**Live Execution** ‚Äî Deployed the agent on real-world prompts to showcase reasoning, tool invocation, and decision-making in action.\n\n**Key Concepts** ‚Äî Illustrated how agents determine when and how to use tools to enhance accuracy and context relevance.\n\n**Why It Matters**\nThis project highlights practical expertise in agentic AI development‚Äîdemonstrating the transition from static LLMs to autonomous, action-driven systems capable of reasoning, planning, and executing tasks. The resulting agent exemplifies how modern AI architectures can blend reasoning with real-world utility","metadata":{}},{"cell_type":"markdown","source":"## **1. Environment Setup**\n\n### **1.1 Import Libraries**\n\n**Overview:**\nThis section initializes the core dependencies required to develop a reasoning-capable AI agent using Google‚Äôs **Agent Development Kit (ADK)** and **Gemini** models.\n\n**Implementation Summary:**\nThe imported libraries enable:\n\n* **Agent Development Kit (ADK)** ‚Äî Provides the foundation for defining autonomous, reasoning-driven agents.\n* **Gemini LLM** ‚Äî Powers the agent‚Äôs cognitive and generative capabilities.\n* **Google Search Tool** ‚Äî Integrates real-time information retrieval into the reasoning workflow.\n* **Type Utilities & Retry Handlers** ‚Äî Support robust API communication and structured error management.\n\n**Technical Insight:**\nBy leveraging ADK‚Äôs high-level abstractions, this setup streamlines agent orchestration‚Äîenabling a focus on **capability design** and **behavioral logic**, rather than low-level implementation details.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nfrom google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\n\nfrom IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:02:14.710078Z","iopub.execute_input":"2025-11-17T02:02:14.710411Z","iopub.status.idle":"2025-11-17T02:02:58.700544Z","shell.execute_reply.started":"2025-11-17T02:02:14.710389Z","shell.execute_reply":"2025-11-17T02:02:58.699533Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### **1.2 API Authentication**\n\n**Overview:**\nThis section implements secure authentication for accessing the **Gemini API**, ensuring credentials are managed according to production-grade security standards.\n\n**Implementation Summary:**\n\n* **Secure Retrieval:** The **UserSecretsClient()** interface is used to fetch the `GOOGLE_API_KEY` from encrypted Kaggle notebook secrets.\n* **Environment Management:** The key is stored in `os.environ`, allowing seamless access by the Gemini client across all runtime components.\n* **Error Handling:** A `try-except` block is included to surface configuration or permission errors early, improving system robustness and debuggability.\n\n**Technical Insight:**\nBy externalizing credentials and avoiding hardcoded tokens, this setup enforces **environmental isolation** and **secure authentication workflows**, minimizing exposure risks. This design also ensures reliable and authorized communication with Google‚Äôs AI services, reducing potential issues related to **rate limiting** or **API authentication failures**.\n","metadata":{}},{"cell_type":"code","source":"try:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Check your notebook secret configuration. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:01:16.716821Z","iopub.execute_input":"2025-11-17T02:01:16.717171Z","iopub.status.idle":"2025-11-17T02:01:16.783004Z","shell.execute_reply.started":"2025-11-17T02:01:16.717147Z","shell.execute_reply":"2025-11-17T02:01:16.781986Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### **1.3 Configure Retry Options**\n\n**Overview:**\nThis section defines a **resilient retry policy** for all Gemini API interactions, ensuring the agent maintains reliability even under transient network or service disruptions.\n\n**Implementation Summary:**\n\n* **Exponential Backoff Strategy:** Configured with an exponential delay (`exp_base=7`), allowing the system to progressively increase wait times between retries and reduce API pressure.\n* **Selective Retry Handling:** Retries are triggered only for recoverable HTTP status codes‚Äî`429` (rate limiting) and server-side errors (`500`, `503`, `504`)‚Äîwhile client-side errors are excluded to prevent unnecessary requests.\n* **Controlled Attempts:** The retry mechanism caps at `5` attempts, with an initial delay of `1s` that scales exponentially across retries.\n\n**Technical Insight:**\nIntegrating structured retry logic enhances **system robustness** and **fault tolerance**, key characteristics of production-grade AI agents. By applying selective backoff and recovery strategies, the agent remains operational during temporary API outages or throttling events‚Äîensuring consistent task execution and improved uptime in live environments.","metadata":{}},{"cell_type":"code","source":"retry_config = types.HttpRetryOptions(\n    attempts=5,       # Maximum retry attempts\n    exp_base=7,       # Delay multiplier\n    initial_delay=1,  # Initial delay before first retry (in seconds)\n    http_status_codes=[429, 500, 503, 504]  # Retry on these error codes\n)\n\nprint(\"‚úÖ Retry configuration initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:03:03.182205Z","iopub.execute_input":"2025-11-17T02:03:03.183517Z","iopub.status.idle":"2025-11-17T02:03:03.188741Z","shell.execute_reply.started":"2025-11-17T02:03:03.183456Z","shell.execute_reply":"2025-11-17T02:03:03.187829Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Retry configuration initialized.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## **2. Define the Agent**\n\n**Overview:**\nThis section configures the core **reasoning agent**, defining its model, behavioral logic, and tool ecosystem. The agent‚Äôs setup combines structured reasoning with real-time adaptability, forming the foundation of its autonomous intelligence.\n\n**Implementation Summary:**\n\n* **Model Selection:** Utilizes **Gemini 2.5 Flash Lite**, optimized for fast inference while maintaining high reasoning accuracy‚Äîideal for iterative, tool-driven interactions.\n* **Tool Integration:** Connects to **Google Search**, enabling access to live, factual data and grounding the agent‚Äôs responses in up-to-date information.\n* **Behavioral Configuration:** Defines clear **system instructions** that guide decision-making, tone, and when to invoke external tools.\n* **Resilience:** Incorporates retry configurations from Section 1.3 to ensure robust communication and consistent performance under variable network conditions.\n\n**Technical Insight:**\nEach parameter serves a targeted purpose:\n\n* `name` ‚Äî Acts as an identifiable handle for logging, tracking, and debugging agent runs.\n* `model=Gemini(...)` ‚Äî Determines the reasoning engine that drives the agent‚Äôs cognitive process.\n* `description` ‚Äî Enables the agent to self-contextualize its role and intended tasks.\n* `instruction` ‚Äî Encodes behavioral constraints and tool invocation logic.\n* `tools=[google_search]` ‚Äî Defines the agent‚Äôs accessible external capabilities.\n\n**Key Insight:**\nBy explicitly instructing the agent on when and how to use **Google Search**, the design achieves **context-aware tool orchestration**‚Äîallowing the system to autonomously decide when external data is necessary for reasoning or verification, a hallmark of effective agentic AI design.","metadata":{}},{"cell_type":"code","source":"# --- 2) Agent instructions (GENERAL, DOMAIN-AGNOSTIC) -------------------------\nINSTRUCTION = \"\"\"\nYou are a reasoning agent. Decide whether to consult external tools (Google Search) based on the query and your uncertainty.\n\nHARD REQUIREMENTS:\n- If the query is time-sensitive, factual, likely to change, or you feel uncertain, you MUST call Google Search at least once BEFORE answering.\n- If you have NOT used Google Search for this query and any of the above conditions apply, DO NOT answer. Instead, reply exactly with: SEARCH_REQUIRED\n\nWhen you use tools:\n- Synthesize results in your own words.\n- Prefer authoritative sources (gov/edu, official orgs, primary docs, reputable encyclopedias).\n- Provide 1‚Äì3 sources.\n\nFinal output format (strict):\n- One concise paragraph with the answer.\n- Then a 'Sources:' list with 1‚Äì3 bullet points (Title ‚Äî URL) IF tools were used.\n- No chain-of-thought or tool UI snippets.\n\nIf the query is ambiguous, ask ONE brief clarifying question before proceeding.\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:23:06.214319Z","iopub.execute_input":"2025-11-17T02:23:06.214713Z","iopub.status.idle":"2025-11-17T02:23:06.219965Z","shell.execute_reply.started":"2025-11-17T02:23:06.214685Z","shell.execute_reply":"2025-11-17T02:23:06.218786Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"root_agent = Agent(\n    name=\"reasoning_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    description=\"An agent that can answer questions by reasoning and searching current facts.\",\n    instruction=INSTRUCTION,\n    tools=[google_search],\n)\n\nprint(\"‚úÖ Reasoning Agent defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:03:06.566911Z","iopub.execute_input":"2025-11-17T02:03:06.567223Z","iopub.status.idle":"2025-11-17T02:03:06.573144Z","shell.execute_reply.started":"2025-11-17T02:03:06.567199Z","shell.execute_reply":"2025-11-17T02:03:06.572289Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Reasoning Agent defined.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import re, io, sys, contextlib\nfrom IPython.display import display, HTML\n\n# ---------- Utilities to normalize ADK responses ----------\ndef _to_event_list(ev):\n    \"\"\"Normalize ADK response into a list of events.\"\"\"\n    if ev is None:\n        return []\n    if isinstance(ev, (list, tuple)):\n        return list(ev)\n    # Some ADK builds return an object with .events or .history\n    for attr in (\"events\", \"history\", \"items\"):\n        if hasattr(ev, attr):\n            seq = getattr(ev, attr)\n            if isinstance(seq, (list, tuple)):\n                return list(seq)\n    # Fallback: treat as single event\n    return [ev]\n\ndef _event_text_single(e) -> str:\n    \"\"\"Extract text from a single Event, robustly.\"\"\"\n    # Try content.parts[].text\n    try:\n        parts = getattr(getattr(e, \"content\", None), \"parts\", None)\n        if parts:\n            for p in parts:\n                if getattr(p, \"text\", None):\n                    t = (p.text or \"\").strip()\n                    if t:\n                        return t\n    except Exception:\n        pass\n    # Try direct .text\n    try:\n        t = getattr(e, \"text\", None)\n        if t:\n            return t.strip()\n    except Exception:\n        pass\n    # Try candidates[0].content.parts[].text\n    try:\n        cands = getattr(e, \"candidates\", None) or []\n        for c in cands:\n            parts = getattr(getattr(c, \"content\", None), \"parts\", None) or []\n            for p in parts:\n                if getattr(p, \"text\", None):\n                    t = (p.text or \"\").strip()\n                    if t:\n                        return t\n    except Exception:\n        pass\n    return \"\"\n\ndef _event_sources_single(e):\n    \"\"\"Extract sources (title, url) from one Event's grounding metadata.\"\"\"\n    out, seen = [], set()\n    try:\n        gm = getattr(e, \"grounding_metadata\", None)\n        chunks = getattr(gm, \"grounding_chunks\", None) or []\n        for ch in chunks:\n            web = getattr(ch, \"web\", None)\n            uri = getattr(web, \"uri\", None)\n            title = getattr(web, \"title\", None) or \"Source\"\n            if uri and uri not in seen:\n                out.append((title, uri))\n                seen.add(uri)\n            if len(out) >= 5:\n                break\n    except Exception:\n        pass\n    return out\n\nURL_RE = re.compile(r\"https?://[^\\s)>\\]]+\", re.IGNORECASE)\n\ndef _urls_from_text(text: str):\n    urls = URL_RE.findall(text or \"\")\n    out, seen = [], set()\n    for u in urls:\n        if u not in seen:\n            out.append((\"Source\", u))\n            seen.add(u)\n        if len(out) >= 5:\n            break\n    return out\n\n# ---------- High-level extractors that work over a list of events ----------\ndef model_text(ev) -> str:\n    \"\"\"Return the last non-empty model text across the event list.\"\"\"\n    events = _to_event_list(ev)\n    last_text = \"\"\n    for e in events:\n        t = _event_text_single(e)\n        if t:\n            last_text = t\n    return last_text\n\ndef extract_sources(ev):\n    \"\"\"Collect sources across all events; fallback to URLs found in final text.\"\"\"\n    events = _to_event_list(ev)\n    srcs, seen = [], set()\n    for e in events:\n        for t,u in _event_sources_single(e):\n            if u not in seen:\n                srcs.append((t,u)); seen.add(u)\n    if not srcs:\n        # fallback: parse URLs from final text\n        txt = model_text(ev)\n        srcs = _urls_from_text(txt)\n    return srcs\n\ndef used_web(ev) -> bool:\n    \"\"\"Detect if any event includes grounding chunks (proxy for Search).\"\"\"\n    events = _to_event_list(ev)\n    for e in events:\n        try:\n            gm = getattr(e, \"grounding_metadata\", None)\n            chunks = getattr(gm, \"grounding_chunks\", None)\n            if chunks:\n                return True\n        except Exception:\n            continue\n    return False\n\n# ---------- Output tidying ----------\nNAME_RE = re.compile(r\"^\\*+\\s*\\*\\*(.+?)\\*\\*\", re.IGNORECASE)\n\ndef dedupe_bullets(text: str) -> str:\n    lines = text.splitlines()\n    seen_names = set()\n    out_lines = []\n    for ln in lines:\n        m = NAME_RE.match(ln.strip())\n        if m:\n            name = m.group(1).strip().lower()\n            if name in seen_names:\n                continue\n            seen_names.add(name)\n        out_lines.append(ln)\n    return \"\\n\".join(out_lines)\n\ndef tidy_paragraphs(text: str) -> str:\n    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n    return text.strip()\n\nPREF_AUTH = (\n    \".gov\", \".edu\", \"aaai.org\", \"neurips.cc\", \"icml.cc\", \"iclr.cc\",\n    \"cvpr.thecvf.com\", \"eccv2025.eu\", \"databricks.com\", \"worldsummit.ai\",\n    \"aisummit.com\", \"aiconference.com\", \"nvidia.com/gtc\",\n    \"acm.org\", \"ieee.org\", \"nature.com\", \"arxiv.org\", \"wikipedia.org\"\n)\n\ndef is_authoritative(url: str) -> bool:\n    u = (url or \"\").lower()\n    return any(dom in u for dom in PREF_AUTH)\n\ndef pick_authoritative(sources, k=3):\n    auth = [s for s in sources if is_authoritative(s[1])]\n    non = [s for s in sources if not is_authoritative(s[1])]\n    seen, out = set(), []\n    for group in (auth, non):\n        for t,u in group:\n            if u not in seen:\n                out.append((t,u)); seen.add(u)\n            if len(out) >= k:\n                return out\n    return out\n\ndef format_final(ev) -> str:\n    main = model_text(ev)\n    if main:\n        main = dedupe_bullets(main)\n        main = tidy_paragraphs(main)\n    else:\n        main = \"(No content returned)\"\n\n    srcs = extract_sources(ev)\n    srcs = pick_authoritative(srcs, k=3)\n\n    if srcs:\n        main += \"\\n\\nSources:\\n\" + \"\\n\".join([f\"- {t} ‚Äî {u}\" for t,u in srcs])\n    return main\n\ndef render_html(text: str):\n    html_lines, in_ul = [], False\n    for line in text.splitlines():\n        if line.startswith(\"- \"):\n            if not in_ul:\n                html_lines.append(\"<ul>\"); in_ul = True\n            html_lines.append(f\"<li>{line[2:]}</li>\")\n        else:\n            if in_ul:\n                html_lines.append(\"</ul>\"); in_ul = False\n            if line.strip():\n                html_lines.append(f\"<p>{line}</p>\")\n            else:\n                html_lines.append(\"<br/>\")\n    if in_ul:\n        html_lines.append(\"</ul>\")\n    html = \"\\n\".join(html_lines)\n    display(HTML(f'<div style=\"line-height:1.55;font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif\">{html}</div>'))\n\n# ---------- Controller: one polished block; no debug spam ----------\nasync def run_and_print(query: str):\n    \"\"\"\n    Uses run_debug (which accepts a prompt) but suppresses its spammy prints.\n    If the query is likely retrieval-worthy and we didn't get sources, nudge twice.\n    \"\"\"\n    def looks_time_sensitive(q: str) -> bool:\n        ql = q.lower()\n        return (\n            any(w in ql for w in (\"last\",\"latest\",\"current\",\"today\",\"schedule\",\"dates\",\"2024\",\"2025\",\"2026\",\"top\",\"best\",\"ranking\",\"conference\",\"summit\",\"workshop\"))\n        )\n\n    def nudge(q: str, note: str):\n        hint = \" Prefer official event sites (neurips.cc, icml.cc, aiconference.com, aisummit.com, worldsummit.ai, databricks.com) or reputable listings.\"\n        return (f\"{note} Use Google Search to verify and collect 2‚Äì3 authoritative sources.{hint} \"\n                f\"Then answer concisely and list the sources.\\nQuery: {q}\")\n\n    buf = io.StringIO()\n    with contextlib.redirect_stdout(buf):\n        ev = await runner.run_debug(query)\n\n    # Enforce retrieval + sources only if it looks like it should have them\n    text = model_text(ev)\n    has_sources = bool(extract_sources(ev))\n    tries = 0\n    while looks_time_sensitive(query) and not has_sources and tries < 2:\n        with contextlib.redirect_stdout(buf):\n            ev = await runner.run_debug(nudge(query, \"Before answering,\"))\n        text = model_text(ev)\n        has_sources = bool(extract_sources(ev))\n        tries += 1\n\n    final_block = format_final(ev)\n    render_html(final_block)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:59:37.266096Z","iopub.execute_input":"2025-11-17T02:59:37.266772Z","iopub.status.idle":"2025-11-17T02:59:37.294066Z","shell.execute_reply.started":"2025-11-17T02:59:37.266742Z","shell.execute_reply":"2025-11-17T02:59:37.293207Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import html\n\ndef format_final(ev) -> str:\n    \"\"\"Produce a clean, deduped block with a single Sources section.\"\"\"\n    main = model_text(ev)\n    if not main:\n        return \"(No content returned)\"\n    # Remove any in-text markdown 'Sources' section from the model output\n    main = re.sub(r\"(?is)(\\*\\*?Sources:?(\\*\\*)?.*?$)\", \"\", main).strip()\n    main = dedupe_bullets(main)\n    main = tidy_paragraphs(main)\n\n    srcs = extract_sources(ev)\n    srcs = pick_authoritative(srcs, k=3)\n\n    if srcs:\n        main += \"\\n\\nSources:\\n\" + \"\\n\".join([f\"- {t} ‚Äî {u}\" for t,u in srcs])\n    return main.strip()\n\n\ndef render_html(text: str):\n    \"\"\"Convert basic markdown to HTML and display nicely.\"\"\"\n    # Escape any stray HTML first\n    text = html.escape(text)\n\n    # Bold **text**\n    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"<b>\\1</b>\", text)\n\n    # Convert * bullets to <ul><li>\n    lines = text.splitlines()\n    html_lines, in_ul = [], False\n    for line in lines:\n        if line.strip().startswith(\"* \"):\n            if not in_ul:\n                html_lines.append(\"<ul>\"); in_ul = True\n            html_lines.append(f\"<li>{line.strip()[2:]}</li>\")\n        else:\n            if in_ul:\n                html_lines.append(\"</ul>\"); in_ul = False\n            if line.strip():\n                html_lines.append(f\"<p>{line}</p>\")\n            else:\n                html_lines.append(\"<br/>\")\n    if in_ul:\n        html_lines.append(\"</ul>\")\n    html_block = \"\\n\".join(html_lines)\n\n    display(\n        HTML(\n            f'<div style=\"line-height:1.6; font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;\">'\n            f\"{html_block}</div>\"\n        )\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T03:01:54.299941Z","iopub.execute_input":"2025-11-17T03:01:54.300248Z","iopub.status.idle":"2025-11-17T03:01:54.309026Z","shell.execute_reply.started":"2025-11-17T03:01:54.300229Z","shell.execute_reply":"2025-11-17T03:01:54.307881Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"## **3. Execute the Agent**\n\n**Overview:**\nThis phase validates the agent‚Äôs end-to-end behavior on real-world prompts‚Äîcapturing how it reasons, decides to invoke tools, and composes grounded answers.\n\n**Execution Focus:**\n\n* **Query Processing:** Evaluate how inputs propagate through the reasoning loop and state updates.\n* **Tool Orchestration:** Inspect when and why **Google Search** is invoked to retrieve or verify up-to-date context.\n* **Answer Synthesis:** Confirm that retrieved evidence is integrated into concise, coherent outputs.\n* **Full Traceability:** Record the complete decision path for post-run analysis and debugging.\n\n**Diagnostics & Observability:**\n`runner.run_debug()` captures a full execution trace, including:\n\n* Internal reasoning checkpoints and intermediate thoughts\n* Tool invocation metadata (parameters, responses, latencies)\n* Final response construction steps\n* Structured logs suitable for performance tuning and error analysis\n\n**Outcome:**\nThese diagnostics establish an auditable reasoning trail and demonstrate production-minded **observability**‚Äîmaking it straightforward to tune prompts, adjust tool policies, and refine retry/backoff parameters under real traffic patterns.","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nprint(\"‚úÖ Runner instantiated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:24:18.754823Z","iopub.execute_input":"2025-11-17T02:24:18.755119Z","iopub.status.idle":"2025-11-17T02:24:18.761031Z","shell.execute_reply.started":"2025-11-17T02:24:18.755099Z","shell.execute_reply":"2025-11-17T02:24:18.760184Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Runner instantiated.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## **3.1 Current-Affairs Query (Example 1)**\n\n**Prompt:** *‚ÄúWho won the last soccer World Cup?‚Äù*\n\n**Intent:**\nDemonstrate the agent‚Äôs ability to handle **time-sensitive, factual queries** that require **real-time retrieval** rather than relying on static training data.\n\n**Expected Behavior:**\n\n* **Temporal Awareness:** Detects that the answer changes over time and that retrieval is required.\n* **Tool Use:** Invokes **Google Search** to fetch authoritative, recent sources.\n* **Grounding & Synthesis:** Consolidates retrieved evidence into a clear, unambiguous answer.\n* **Citations/Traceability:** Surfaces the reasoning trace and tool responses in debug logs for verification.\n\n**Evaluation Signals (what this run proves):**\n\n* The **decision policy** correctly routes to the Search tool for dynamic facts.\n* The **reasoning loop** integrates external evidence before generating the final reply.\n* The **retry/backoff** policy holds under real API conditions without silent failure.\n* The **observability** layer (debug trace) provides end-to-end provenance.\n\n**Example Invocation (conceptual):**\n\n* **Input:** ‚ÄúWho won the last soccer World Cup?‚Äù\n* **Agent Actions:**\n\n  1. Classifies as time-sensitive ‚Üí 2) Calls `google_search` with focused query ‚Üí\n  2. Parses recent results ‚Üí 4) Generates a grounded answer with source-backed confidence.\n\n**Acceptance Criteria:**\n\n* Final answer names the **correct champion** and **edition/year**.\n* Debug trace shows at least **one successful tool call** and **no client-error retries**.\n* Latency remains within acceptable bounds for interactive use (validated in logs).\n\n**Why this example belongs in the showcase:**\nIt isolates a core competency of **agentic systems**‚Äî**context-aware tool orchestration**‚Äîand demonstrates that the agent reliably transitions from reasoning to action to verified output on a changing factual landscape.","metadata":{}},{"cell_type":"code","source":"await run_and_print(\"Who won the last soccer World Cup?\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T03:02:11.637157Z","iopub.execute_input":"2025-11-17T03:02:11.637780Z","iopub.status.idle":"2025-11-17T03:02:13.590018Z","shell.execute_reply.started":"2025-11-17T03:02:11.637755Z","shell.execute_reply":"2025-11-17T03:02:13.589209Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div style=\"line-height:1.6; font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;\"><p>Argentina won the last soccer World Cup, which was held in 2022. They defeated France in a dramatic final match that ended 3-3 after extra time, ultimately winning the penalty shootout 4-2. This marked Argentina&#x27;s third World Cup title.</p>\n<br/>\n<p>Sources:</p>\n<p>- Source ‚Äî https://www.fifa.com/tournaments/mens/worldcup/qatar2022/match-report/report%3Dfinal-match</p>\n<p>- Source ‚Äî https://www.bbc.com/sport/football/63964199</p>\n<p>- Source ‚Äî https://www.espn.com/soccer/match/report/_/gameId/639441433</p></div>"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"## **3.2 Research-Oriented Query (Example 2)**\n\n**Prompt:** *‚ÄúWhat are the top AI conferences in 2025?‚Äù*\n\n**Intent:**\nDemonstrate the agent‚Äôs ability to handle **open-ended research queries** that demand **multi-source retrieval**, **reasoning over trends**, and **synthesized narrative formation**‚Äîrather than merely returning discrete facts.\n\n**Expected Behavior:**\n\n* **Query Characterization:** Detects that the user is requesting a structured overview of events in 2025, not just a single fact.\n* **Comprehensive Retrieval:** Executes one or more calls to the search tool to harvest up-to-date listings, major announcements, and schedule shifts for AI conferences.\n* **Reasoning & Synthesis:**\n\n  * Identifies major conferences (e.g., NeurIPS 2025, ICML 2025, CVPR 2025) and any new emerging formats.\n  * Highlights key trends (e.g., increased focus on generative AI ethics, agent-based models, hybrid on-site/virtual formats).\n  * Organizes the output into clear sections (e.g., Conference Overview, Key Themes, Emerging Formats, Why It Matters).\n* **Traceability:** The debug log shows multiple search tool invocations, their results, and reasoning steps combining them into the final answer.\n\n**Evaluation Signals (what this run demonstrates):**\n\n* The agent transitions from retrieval to **analysis** (not just listing).\n* It shows **pattern identification** (e.g., ‚ÄúIn 2025 the theme across top conferences is‚Ä¶‚Äù) rather than static reporting.\n* It maintains **robustness** under potentially variable search results (e.g., new or shifted conferences).\n* The observability layer provides a full trace of tool calls, intermediate logic, and final synthesis.\n\n**Acceptance Criteria:**\n\n* Final answer enumerates 4-6 key AI conferences in 2025 with brief descriptions (location/form, highlights, relevance).\n* The reasoning includes topical themes and signals why each conference is notable in 2025.\n* No uncited leaps; evidence in trace supports conclusions.\n* Execution logs show retrieval depth (i.e., more than one source) and coherent reasoning.\n\n**Why this example belongs in the showcase:**\nIt underscores the agent‚Äôs **higher-order capabilities**: not just retrieving facts, but **connecting data**, **identifying trends**, and **communicating structured insights**‚Äîa clear demonstration of agentic AI in a practical, modern domain.\n","metadata":{}},{"cell_type":"code","source":"await run_and_print(\"What are the top AI conferences in 2025?\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T03:02:00.468611Z","iopub.execute_input":"2025-11-17T03:02:00.469254Z","iopub.status.idle":"2025-11-17T03:02:03.634447Z","shell.execute_reply.started":"2025-11-17T03:02:00.469217Z","shell.execute_reply":"2025-11-17T03:02:03.633662Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div style=\"line-height:1.6; font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;\"><p>The top AI conferences in 2025 offer a diverse range of opportunities for professionals and researchers to engage with the latest advancements in artificial intelligence. These events span academic research, industry applications, and ethical considerations.</p>\n<br/>\n<p>Key AI conferences scheduled for 2025 include:</p>\n<br/>\n<ul>\n<li>  <b>Data + AI Summit:</b> Held June 9-12 in San Francisco, this hybrid event by Databricks focuses on data analytics, AI technology, data engineering, and machine learning.</li>\n<li>  <b>SuperAI:</b> Taking place in Singapore from June 18-19, SuperAI is a major AI summit in Asia, attracting global leaders and innovators in AI.</li>\n<li>  <b>The AI Summit London:</b> Scheduled for June 11-12 in London, this conference explores commercial AI applications and industry innovation.</li>\n<li>  <b>Ai4 2025:</b> This conference will be held August 11-13 in Las Vegas, billed as North America&#x27;s largest AI event, with a broad focus on AI implementation across various industries.</li>\n<li>  <b>World Summit AI:</b> This global summit will convene in Amsterdam on October 8-9, addressing the AI agenda, including generative AI and scaling AI startups.</li>\n<li>  <b>International Conference on Machine Learning (ICML):</b> The 42nd edition is set for July 13-19 in Vancouver, Canada, serving as a premier academic venue for machine learning research.</li>\n<li>  <b>AI Infra Summit:</b> Previously known as the AI Hardware &amp; Edge AI Summit, this conference will be held September 9-11 in Santa Clara, California, focusing on AI infrastructure, including data centers and edge AI.</li>\n<li>  <b>The AI Conference San Francisco:</b> Scheduled for September 17-18 in San Francisco, this event delves into applied AI, generative AI, foundational models, and practical AI deployment.</li>\n<li>  <b>NeurIPS 2025:</b> The Thirty-Ninth Annual Conference on Neural Information Processing Systems will take place December 2-7 in San Diego, California, presenting advances in machine learning and artificial intelligence.</li>\n<li>  <b>AIAI 2025 (Artificial Intelligence Applications and Innovations):</b> This hybrid event will be held February 3-4 in Limassol, Cyprus, focusing on AI research and collaboration.</li>\n<li>  <b>Eighth AAAI/ACM Conference on AI, Ethics, and Society (AIES-25):</b> Scheduled for October 20-22 in Madrid, Spain, this conference concentrates on the ethical aspects of AI.</li>\n</ul>\n<br/>\n<p>These conferences provide valuable insights and networking opportunities for anyone involved in the field of artificial intelligence.</p>\n<br/>\n<p>Sources:</p>\n<p>- datacamp.com ‚Äî https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGW1luZdwDExYWJ3oI6GFLG1myfI8w1xw6nLmrdJ6_OC8gQpiarmoi8Drd0E0-KQJ1NMmr1FU1nJy2f2VC-KGTKeIyHVSLRass23DeK7o9igmP5ZVIi3MjJzNuvMSxhP9nsAdcFvNyGZX0yEg==</p>\n<p>- digitalocean.com ‚Äî https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGmBG-zD-zta-_nIhLc1lp48RRweSqTLKsRm-m2uWqfBDosIq2KJJZpQT4zmrxKILzPf6t0NRI5baoKKpciJzjDEteV1nFJmg0pdG28shl2Xk4iZoaKkv8CXil2zBytwdWnOHACvnKyDn1XUOhyCHTSUE-k1FuJzv0ac76AayY=</p>\n<p>- aiconferences.ai ‚Äî https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEZNIKgU1D4dCSTfzBRavNYvRTVNjOjrRLIAPQEjU1lr5WjAeIsOoVZYTH2ppthcrrhkiI9zhVGEidt5RXQfH6Gpxxcxdogv_cg3wf_h-sYlXf81oQ=</p></div>"},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"## **4. Agent Reasoning and Action Flow**\n\n**Overview:**\nThe agent‚Äôs decision process follows a **reasoning-first architecture**. Upon receiving a query, it evaluates whether sufficient context exists within its internal knowledge. If uncertainty is detected, it autonomously invokes the **Google Search tool** to retrieve current and relevant data.\n\n**Workflow Summary:**\n\n1. **Intent Recognition:** Classifies the query as factual, time-sensitive, or analytical.\n2. **Reasoning Pass:** Determines whether its internal context can yield a reliable answer.\n3. **Tool Invocation:** When external data is required, the agent issues structured search queries.\n4. **Evidence Integration:** Synthesizes retrieved results into a coherent, well-grounded response.\n5. **Traceable Output:** Each reasoning step, tool call, and synthesis stage is captured for observability and debugging.\n\n**Key Insight:**\nThis **traceable reasoning loop** exemplifies modern agentic AI‚Äîsystems that not only generate answers but also **decide, act, and explain** their decision path. The integration of reasoning transparency and tool autonomy reflects production-grade design principles for intelligent, accountable systems.","metadata":{}},{"cell_type":"markdown","source":"## **5. Project Summary**\n\n**Outcome Overview:**\nThis project delivers a complete demonstration of building and deploying a **reasoning-capable AI agent** using **Google‚Äôs Agent Development Kit (ADK)** and **Gemini** models.\n\n**Key Achievements:**\n\n* **End-to-End Implementation:** Covered environment setup, secure API authentication, agent definition, retry resilience, and live query execution.\n* **Demonstrated Reasoning Capabilities:** The agent autonomously determined when to use tools, executed real-time searches, and synthesized results.\n* **Transparent Workflows:** Every decision and tool call was fully traceable through debug outputs.\n* **Reproducible Design:** All configurations and outputs are documented for consistent replication or extension.\n\n**Professional Impact:**\nThis notebook exemplifies hands-on **agentic AI proficiency**, bridging model reasoning, tool orchestration, and observability. It serves as a strong portfolio artifact showcasing the ability to **design, implement, and interpret intelligent autonomous systems**.","metadata":{}},{"cell_type":"markdown","source":"## üîó Next Steps: From Reasoning to Multi-Agent Architectures\n\nThis notebook focused on designing a single reasoning agent using Google‚Äôs ADK and Gemini ‚Äî demonstrating tool use, action selection, and grounded reasoning.\n\nIn the next phase, I extend this foundation to explore **multi-agent architectures**, where multiple specialized agents (Planner, Researcher, Summarizer) collaborate to solve complex tasks.\n\nüëâ [Continue to the next notebook: *Multi-Agent Architectures with ADK & Gemini*](https://www.kaggle.com/code/kanikaw/agentic-ai-architectures-sequential-parallel-l)\n","metadata":{}}]}